{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/PyTorch/blob/master/PyTorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAOHHDYbEu2_",
        "colab_type": "text"
      },
      "source": [
        "# PyTorchのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlpBf3IKDFa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WwXlb0YDmQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsyLenx3E0b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDudM7UfFbDV",
        "colab_type": "text"
      },
      "source": [
        "インストールできたかの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q78xEOX1FQbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ge4WLbSFe2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.tensor([1, 2, 3]).to(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj_rcAHbNNs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ed916e6e-2c7e-4c05-9ed2-49961541b27e"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLBrtJ1pNTM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1b1c1a32-7262-400d-a426-ac0a025d9905"
      },
      "source": [
        "# drive mean root directory of  google drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls drive/\"Colab Notebooks\"/PyTorch"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n",
            "FashionMNIST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7mKuLxYk-9t",
        "colab_type": "text"
      },
      "source": [
        "# Chapter4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0H1assajpbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zExRIQeHQWFr",
        "colab_type": "text"
      },
      "source": [
        "## データの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH9e8uryLVwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "01365eaa-d884-4f48-c1de-88983b0154e2"
      },
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# 訓練用のデータを取得\n",
        "# そのままだとPython Imaging Libraryの画像形式でDatasetを作ってしまうので、transforms.ToTensorでTensorに変換する\n",
        "fashion_mnist_train = FashionMNIST(\"drive/Colab Notebooks/PyTorch/FashionMNIST\",\n",
        "                                   train=True,\n",
        "                                   download=True,\n",
        "                                   transform=transforms.ToTensor())\n",
        "\n",
        "# 検証用データの取得\n",
        "fashion_mnist_test = FashionMNIST(\"drive/Colab Notebooks/PyTorch/FashionMNIST\",\n",
        "                                  train=False,\n",
        "                                  download=True,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "# バッチサイズが128のDataLoaderをそれぞれ作成\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(fashion_mnist_train,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(fashion_mnist_test,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:04, 5795878.96it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 36419.07it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:02, 1675200.29it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 15081.43it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to drive/Colab Notebooks/PyTorch/FashionMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT77GFFbQakF",
        "colab_type": "text"
      },
      "source": [
        "## CNNの構築と学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BXxdvJgOuhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "745d172f-eeb8-4162-98e6-dc9e5cc5fa87"
      },
      "source": [
        "# (N, C, H, W)形式のTensorを(N, C*H*Wに引き伸ばす層)\n",
        "# C:color, H:height, W:width\n",
        "# 畳み込み層の出力をMLPに渡す際に必要\n",
        "class FlattenLayer(nn.Module):\n",
        "  def forward(self, x):\n",
        "    sizes = x.size()\n",
        "    return x.view(sizes[0], -1)\n",
        "\n",
        "# 5×5のカーネルを使用し、最初に32個、次に64個のチャンネルを作成する\n",
        "# BatchNorm2dは画像形式用のBatch Normalization\n",
        "# Dropout2dは画像形式用のDropout\n",
        "# 最後にFlattenLayerを挟む\n",
        "conv_net = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.Dropout2d(0.25),\n",
        "    nn.Conv2d(32, 64, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.Dropout2d(0.25),\n",
        "    FlattenLayer()\n",
        ")\n",
        "\n",
        "# 畳み込みによって最終的にどうようなサイズになっているかを実際にダミーデータを入れてみて確認する\n",
        "test_input = torch.ones(1, 1, 28, 28)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "conv_output_size"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqyU5GMKQHN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d85b4dea-8315-46f6-8670-b2b2eb45ed9b"
      },
      "source": [
        "# 2層のMLP\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(conv_output_size, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(200),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Linear(200, 10)\n",
        ")\n",
        "\n",
        "# 最終的なCNN\n",
        "net = nn.Sequential(\n",
        "    conv_net,\n",
        "    mlp\n",
        ")\n",
        "\n",
        "net"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout2d(p=0.25, inplace=False)\n",
              "    (5): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): ReLU()\n",
              "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): FlattenLayer()\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtttSeevQHXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 評価のヘルパー関数\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "  # DropoutやBatchNormを無効化\n",
        "  net.eval()\n",
        "\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "\n",
        "  for x, y in data_loader:\n",
        "    # toメソッドで計算を実行するデバイスに転送する\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # 確率が最大のクラスを予測\n",
        "    # ここではforwardの計算だけなので自動微分に必要な処理はoffにして余計な計算を省く\n",
        "    with torch.no_grad():\n",
        "      _, y_pred = net(x).max(1)\n",
        "\n",
        "    ys.append(y)\n",
        "    ypreds.append(y_pred)\n",
        "\n",
        "    # ミニバッチごとの予測結果などを1つにまとめる\n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "\n",
        "    # 予測精度を計算\n",
        "    acc = (ys == ypreds).float().sum()/len(ys)\n",
        "    return acc.item()\n",
        "\n",
        "# 訓練のヘルパー関数\n",
        "def train_net(net, train_loader, test_loader,\n",
        "              optimizer_cls=optim.Adam,\n",
        "              loss_fn=nn.CrossEntropyLoss(),\n",
        "              n_iter=10,device=\"cpu\"):\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "  val_acc = []\n",
        "  optimizer = optimizer_cls(net.parameters())\n",
        "\n",
        "  for epoch in range(n_iter):\n",
        "    running_loss = 0.0\n",
        "    # ネットワークを訓練モードにする\n",
        "    net.train()\n",
        "    n = 0\n",
        "    n_acc = 0\n",
        "    # 非常に時間がかかるのでtqdmを使用してプログレスバーを出す\n",
        "    for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "                                  total = len(train_loader)):\n",
        "      xx = xx.to(device)\n",
        "      yy = yy.to(device)\n",
        "\n",
        "      h = net(xx)\n",
        "      loss = loss_fn(h, yy)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      n += len(xx)\n",
        "      _, y_pred = h.max(1)\n",
        "      n_acc += (yy == y_pred).float().sum().item()\n",
        "    train_losses.append(running_loss / i)\n",
        "\n",
        "    # 訓練データの予測精度\n",
        "    train_acc.append(n_acc / n)\n",
        "\n",
        "    # 検証データの予測精度\n",
        "    val_acc.append(eval_net(net, test_loader, device))\n",
        "\n",
        "    # このepochでの結果の表示\n",
        "    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjcFkGJrUPU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "8e784431-16a6-4c1d-d235-d6f4758b562d"
      },
      "source": [
        "# ネットワークの全パラメータをGPUに転送\n",
        "net.to(\"cuda:0\")\n",
        "\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=20,device=\"cuda:0\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:06<00:00, 71.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.45682357754717523 0.8358666666666666 0.8359375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 0.3240702795740376 0.8827666666666667 0.859375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 71.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 0.28973247282780135 0.8943333333333333 0.8828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 71.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 0.2684848619959293 0.9017666666666667 0.8671875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 71.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 0.25108556135788435 0.9082166666666667 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 0.24210758459491608 0.9103333333333333 0.921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 72.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 0.2290971502980106 0.9160833333333334 0.9296875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 71.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 0.2172598009212659 0.92075 0.921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 72.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 0.20908908698803338 0.9235166666666667 0.90625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 72.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 0.20331461487226507 0.9233166666666667 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 71.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 0.198938514607457 0.9259333333333334 0.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11 0.19103083863026565 0.9288 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12 0.1840683861961986 0.9320833333333334 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13 0.1795149413216063 0.93185 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 72.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14 0.1769038920696729 0.93365 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:06<00:00, 73.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15 0.17348694175672838 0.9361333333333334 0.9140625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 72.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "16 0.16575692240626383 0.9377833333333333 0.921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17 0.16410207822441292 0.9399166666666666 0.90625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:06<00:00, 73.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "18 0.15877481164713192 0.9400666666666667 0.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 469/469 [00:06<00:00, 73.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19 0.1558684255195479 0.9421333333333334 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqcViC7LeE3N",
        "colab_type": "text"
      },
      "source": [
        "## 転移学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoXaVVNCUcFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7a01f15a-5e97-450f-f9a0-937501004e44"
      },
      "source": [
        "!wget https://github.com/lucidfrontier45/PyTorch-Book/raw/master/data/taco_and_burrito.tar.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-01 06:37:08--  https://github.com/lucidfrontier45/PyTorch-Book/raw/master/data/taco_and_burrito.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lucidfrontier45/PyTorch-Book/master/data/taco_and_burrito.tar.gz [following]\n",
            "--2019-12-01 06:37:09--  https://raw.githubusercontent.com/lucidfrontier45/PyTorch-Book/master/data/taco_and_burrito.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15292798 (15M) [application/octet-stream]\n",
            "Saving to: ‘taco_and_burrito.tar.gz’\n",
            "\n",
            "taco_and_burrito.ta 100%[===================>]  14.58M  96.1MB/s    in 0.2s    \n",
            "\n",
            "2019-12-01 06:37:11 (96.1 MB/s) - ‘taco_and_burrito.tar.gz’ saved [15292798/15292798]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3LbmM7qeWWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -zxvf taco_and_burrito.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxySio--ezsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mv taco_and_burrito drive/\"Colab Notebooks\"/PyTorch/taco_and_burrito"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0iITXWmg4ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# ImageFolder関数を使用してDatasetを作成する\n",
        "train_imgs = ImageFolder(\n",
        "    \"drive/Colab Notebooks/PyTorch/taco_and_burrito/train\",\n",
        "    transform = transforms.Compose([transforms.RandomCrop(224),\n",
        "                                        transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "test_imgs = ImageFolder(\n",
        "    \"drive/Colab Notebooks/PyTorch/taco_and_burrito/test\",\n",
        "    transform = transforms.Compose([transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_loader = DataLoader(train_imgs, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_imgs, batch_size=32, shuffle=False) # テストの方はシャッフルしない。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5KT8Eriy5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7654bc3-ce5e-4768-c759-be9ea0a10269"
      },
      "source": [
        "print(train_imgs.classes)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['burrito', 'taco']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyXBkjfBjFA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "246f17f9-ce59-407c-a2ba-d4df10f8ef04"
      },
      "source": [
        "print(train_imgs.class_to_idx)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'burrito': 0, 'taco': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNTjaNmUjRHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dea9874a-2ea8-4508-d5a6-0942454b6a7c"
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "# 事前学習済みのresnet18をロード\n",
        "net = models.resnet18(pretrained=True)\n",
        "\n",
        "# 全てのパラメータを自動微分対象外にする\n",
        "for p in net.parameters():\n",
        "  p.requires_grad=False\n",
        "\n",
        "# 最後の線形層を付け替える\n",
        "fc_input_dim = net.fc.in_features\n",
        "net.fc = nn.Linear(fc_input_dim, 2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 218MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byenYY7eliOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの訓練関数\n",
        "\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "  # DropoutやBatcNormを無効化\n",
        "  net.eval()\n",
        "\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "\n",
        "  for x, y in data_loader:\n",
        "    # toメソッドで計算を実行するデバイスに転送する\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # 確率が最大のクラスを予測\n",
        "    # ここではforwardの計算だけなので自動微分に必要な処理はoffにして余計な計算を省く\n",
        "    with torch.no_grad():\n",
        "      _, y_pred = net(x).max(1)\n",
        "\n",
        "    ys.append(y)\n",
        "    ypreds.append(y_pred)\n",
        "\n",
        "  # ミニバッチごとの予測結果などを1つにまとめる\n",
        "  ys = torch.cat(ys)\n",
        "  ypreds = torch.cat(ypreds)\n",
        "\n",
        "  # 予測精度を計算\n",
        "  acc = (ys == ypreds).float().sum() / len(ys)\n",
        "  return acc.item()\n",
        "\n",
        "\n",
        "def train_net(net, train_loader, test_loader,\n",
        "              only_fc = True,\n",
        "              optimizer_cls=optim.Adam,\n",
        "              loss_fn=nn.CrossEntropyLoss(),\n",
        "              n_iter=10,\n",
        "              device=\"cpu\"):\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "  val_acc = []\n",
        "  if only_fc:\n",
        "    # 最後の線形層のパラメータのみをoptimizerに渡す\n",
        "    optimizer = optimizer_cls(net.fc.parameters())\n",
        "  else:\n",
        "    optimizer = optimizer_cls(net.parameters())\n",
        "\n",
        "  for epoch in range(n_iter):\n",
        "    running_loss = 0.0\n",
        "    # ネットワークを訓練モードにする\n",
        "    net.train()\n",
        "    n = 0\n",
        "    n_acc = 0\n",
        "\n",
        "    # 非常に時間がかかるのでtqdmを使用してプログレスバーを出す\n",
        "    for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "                                 total=len(train_loader)):\n",
        "      xx = xx.to(device)\n",
        "      yy = yy.to(device)\n",
        "\n",
        "      h = net(xx)\n",
        "      loss = loss_fn(h, yy)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      n += len(xx)\n",
        "      _, y_pred = h.max(1)\n",
        "      n_acc += (yy == y_pred).float().sum().item()\n",
        "\n",
        "    train_losses.append(running_loss / i)\n",
        "\n",
        "    # 訓練データの予測精度\n",
        "    train_acc.append(n_acc / n)\n",
        "\n",
        "    # 検証データの予測精度\n",
        "    val_acc.append(eval_net(net, test_loader, device))\n",
        "\n",
        "    # このepochでの結果を表示\n",
        "    print(epoch, train_losses[-1], train_acc[-1],\n",
        "          val_acc[-1], flush=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaGH0oPxKIt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "fa0e4b3c-321c-437c-e6ff-bb20ed2bac83"
      },
      "source": [
        "# ネットワークの全パラメータをGPUに転送\n",
        "net.to(\"cuda:0\")\n",
        "\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:04<00:00,  5.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.7108825228431008 0.5702247191011236 0.6833333969116211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  5.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 0.5333546210419048 0.7654494382022472 0.8500000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 0.4702928811311722 0.8103932584269663 0.8500000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 0.41168592192909936 0.8497191011235955 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 0.42356702008030633 0.8286516853932584 0.8333333730697632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 0.3925206180323254 0.8609550561797753 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 0.3644094081087546 0.848314606741573 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 0.3780453347346999 0.8525280898876404 0.8500000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 0.33898242156613956 0.8806179775280899 0.8666667342185974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 0.356334848837419 0.8426966292134831 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 0.3495618470690467 0.8679775280898876 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11 0.3250801163640889 0.8581460674157303 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12 0.3302149684591727 0.8581460674157303 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13 0.3315032497048378 0.8735955056179775 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14 0.3241987831213258 0.8862359550561798 0.8500000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15 0.33529087426987564 0.8567415730337079 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "16 0.30489537797190924 0.8890449438202247 0.8666667342185974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17 0.28614081781018863 0.898876404494382 0.8666667342185974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "18 0.2856492914936759 0.8918539325842697 0.8833333849906921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19 0.2961136874827472 0.875 0.8666667342185974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4eQDtjP9Hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fine tuningの別の書き方\n",
        "\n",
        "class IdentityLayer(nn.Module):\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "  \n",
        "net = models.resnet18(pretrained=True)\n",
        "for p in net.parameters():\n",
        "  p.requires_grad=False\n",
        "net.fc = IdentityLayer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deNLUkWdR2Pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c18ac0c-9f5b-46eb-d7f7-1964fb70471d"
      },
      "source": [
        "# 転移学習を使わない場合どうなるか\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.Conv2d(32, 64, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.Conv2d(64, 128, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(128),\n",
        "    FlattenLayer()\n",
        ")\n",
        "\n",
        "# 畳み込みによってどのようなサイズになっているかを実際にデータを入れて確認する\n",
        "test_input = torch.ones(1, 3, 224, 224)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "conv_output_size"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMRyRLTVSBvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0ad39ce6-46de-4fa0-a2c0-7c0d659721aa"
      },
      "source": [
        "# 最終的なCNN\n",
        "net = nn.Sequential(\n",
        "    conv_net,\n",
        "    nn.Linear(conv_output_size, 2)\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=10,only_fc=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:55<00:00,  4.00s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 4.477879944172773 0.5828651685393258 0.6166666746139526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:54<00:00,  3.99s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 5.907462442463094 0.5730337078651685 0.699999988079071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:54<00:00,  4.00s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 5.13866278258237 0.6179775280898876 0.6000000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:54<00:00,  4.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 5.080085786906156 0.6053370786516854 0.6833333373069763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:55<00:00,  3.99s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 5.568163015625694 0.6320224719101124 0.5833333134651184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 11/23 [00:56<01:01,  5.16s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhrb4GNJSB1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcDEeMGfSB59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}