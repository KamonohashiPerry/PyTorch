{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/PyTorch/blob/master/PyTorch_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psUl7qkT4uNE",
        "colab_type": "text"
      },
      "source": [
        "# PyTorchのインストール\n",
        "+ Colabの編集→ノートブックの設定でGPUモードにすることをお忘れなく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk5T777J4OE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMAYS8QJ4wHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbBwXiN40MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPWZNZX346jj",
        "colab_type": "text"
      },
      "source": [
        "インストールできたかの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN__77Ap417w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPctnygX4-12",
        "colab_type": "code",
        "outputId": "fc3b1f5c-d5ba-42a2-b39f-704849c4a3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.tensor([1, 2, 3]).to(\"cuda:0\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iiN-QLZ5BiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vFtGVjP5JKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # drive mean root directory of  google drive\n",
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive\n",
        "# !ls drive/\"Colab Notebooks\"/PyTorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PSPHCNt5JWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
        "import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iELizoi95Jbq",
        "colab_type": "code",
        "outputId": "83cad04b-07e2-4543-ee5f-d42fdd43d5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-22 13:16:02--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4752884 (4.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   4.53M  1.49MB/s    in 3.0s    \n",
            "\n",
            "2019-12-22 13:16:05 (1.49 MB/s) - ‘spa-eng.zip’ saved [4752884/4752884]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SqR5xdm5gyl",
        "colab_type": "code",
        "outputId": "db561c4d-20ae-4be9-9fac-5daf1764945a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip spa-eng.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI5clEZu5sGe",
        "colab_type": "code",
        "outputId": "a23b434f-fbff-47b2-9ecb-7080e82f1279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_about.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/  spa-eng.zip  spa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT2IPp3m11gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"spa.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adJhKR1w5te9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import collections\n",
        "import itertools\n",
        "\n",
        "remove_marks_regex = re.compile(\"[\\,\\(\\)\\[\\]\\*:;¿¡]|<.*?>\")\n",
        "shift_marks_regex = re.compile(\"([?!\\.])\")\n",
        "\n",
        "unk = 0\n",
        "sos = 1\n",
        "eos = 2\n",
        "\n",
        "def normalize(text):\n",
        "  # 小文字にする\n",
        "  text = text.lower()\n",
        "  # 不要な文字を除去\n",
        "  text = remove_marks_regex.sub(\"\", text)\n",
        "  # ?!.と単語の間に空白を挿入\n",
        "  text = shift_marks_regex.sub(r\" \\1\", text)\n",
        "  return text\n",
        "\n",
        "def parse_line(line):\n",
        "  line = normalize(line.strip())\n",
        "  # 翻訳元(src)と翻訳先(trg)それぞれのトークンのリストを作る\n",
        "  src, trg, _ = line.split(\"\\t\")\n",
        "  src_tokens = src.strip().split()\n",
        "  trg_tokens = trg.strip().split()\n",
        "  return src_tokens, trg_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U12yoztS7VBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(tokens):\n",
        "  # ファイル中の全ての文章でのトークンの出現数を数える\n",
        "  counts = collections.Counter(tokens)\n",
        "  # トークンの出現数の多い順に並べる\n",
        "  sorted_counts = sorted(counts.items(),\n",
        "                            key=lambda c: c[1], reverse=True)\n",
        "  # 3つのタグを追加して正引きリストと逆引き用辞書を作る\n",
        "  word_list = [\"<UNK>\", \"<SOS>\", \"<EOS>\"] + [x[0] for x in sorted_counts]\n",
        "  word_dict = dict((w, i) for i, w in enumerate(word_list))\n",
        "  return word_list, word_dict\n",
        "\n",
        "def words2tensor(words, word_dict, max_len, padding=0):\n",
        "  # 末尾に終了タグをつける\n",
        "  words = words + [\"<EOS>\"]\n",
        "  # 辞書を利用して数値のリストに変換する\n",
        "  words = [word_dict.get(w, 0) for w in words]\n",
        "  seq_len = len(words)\n",
        "  # 長さがmax_len以下の場合はパディングする\n",
        "  if seq_len < max_len + 1:\n",
        "    words = words + [padding] * (max_len + 1 - seq_len)\n",
        "    # Tensorに変換して返す\n",
        "  return torch.tensor(words, dtype=torch.int64), seq_len\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h9fd9QCA6SLZ",
        "colab": {}
      },
      "source": [
        "class TranslationPairDataset(Dataset):\n",
        "  def __init__(self, path, max_len=15):\n",
        "    # 単語数が多い文章をフィルタリングする関数\n",
        "    def filter_pair(p):\n",
        "      return not (len(p[0]) > max_len or len(p[1]) > max_len )\n",
        "\n",
        "    # ファイルを開き、パース/フィルタリングをする\n",
        "    with open(path) as fp:\n",
        "      pairs = map(parse_line, fp)\n",
        "      pairs = filter(filter_pair, pairs)\n",
        "      pairs = list(pairs)\n",
        "\n",
        "    # 文章のペアをソースとターゲットに分ける\n",
        "    src = [p[0] for p in pairs]\n",
        "    trg = [p[1] for p in pairs]\n",
        "    # それぞれの語彙集を作成する\n",
        "    self.src_word_list, self.src_word_dict = build_vocab(itertools.chain.from_iterable(src))\n",
        "    self.trg_word_list, self.trg_word_dict = build_vocab(itertools.chain.from_iterable(trg))\n",
        "\n",
        "    # 語彙集を使用してTensorに変換する\n",
        "    self.src_data = [words2tensor(\n",
        "        words, self.src_word_dict, max_len)\n",
        "          for words in src]\n",
        "\n",
        "    # -100でパディングすることでPyTorchの損失関数の計算に含めないようにするらしい。\n",
        "    # 可変長の系列の扱いが容易になるらしい。\n",
        "    self.trg_data = [words2tensor(\n",
        "        words, self.trg_word_dict, max_len, -100)\n",
        "          for words in trg]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    src, lsrc = self.src_data[idx]\n",
        "    trg, ltrg = self.trg_data[idx]\n",
        "    return src, lsrc, trg, ltrg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d5c64b2-5532-4fe0-95f0-66877c6c2a29",
        "id": "oP_S9ajj6Pm0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PCA1S0yx1TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DatasetとDataLoaderの作成\n",
        "batch_size = 64\n",
        "max_len = 10\n",
        "\n",
        "path = \"/content/spa.txt\"\n",
        "ds = TranslationPairDataset(path, max_len=max_len)\n",
        "loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m9FlKWE5D6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoderの作成\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_embeddings,\n",
        "               embedding_dim=50,\n",
        "               hidden_size=50,\n",
        "               num_layers=1,\n",
        "               dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim,\n",
        "                            padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embedding_dim,\n",
        "                        hidden_size,\n",
        "                        num_layers,\n",
        "                        batch_first=True,\n",
        "                        dropout=dropout)\n",
        "    \n",
        "  def forward(self, x, h0=None, l=None):\n",
        "    x = self.emb(x)\n",
        "    if l is not None:\n",
        "      x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
        "    # 内部状態のみをDecoderにわたすので、出力は破棄している。\n",
        "    _, h = self.lstm(x, h0)\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg5SdijN9Fu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoderの作成\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_embeddings,\n",
        "               embedding_dim=50,\n",
        "               hidden_size=50,\n",
        "               num_layers=1,\n",
        "               dropout=0.2):\n",
        "    super().__init__()\n",
        "    # 畳み込み層\n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim,padding_idx=0)\n",
        "    # LSTM\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_size,\n",
        "                        num_layers,batch_first=True,\n",
        "                        dropout=dropout)\n",
        "    # 線形\n",
        "    self.linear = nn.Linear(hidden_size, num_embeddings)\n",
        "\n",
        "  def forward(self, x, h, l=None):\n",
        "    x = self.emb(x)\n",
        "    if l is not None:\n",
        "      x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
        "    x, h = self.lstm(x, h)\n",
        "    if l is not None:\n",
        "      x = nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0)[0]\n",
        "    x = self.linear(x)\n",
        "    return x, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaK3zAWU-z4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 翻訳する関数の作成\n",
        "def translate(input_str, enc, dec, max_len=15,\n",
        "              device=\"cpu\"):\n",
        "  # 入力文字列を数値化してTensorに変換\n",
        "  words = normalize(input_str).split()\n",
        "  input_tensor, seq_len = words2tensor(words, ds.src_word_dict, max_len=max_len)\n",
        "  input_tensor = input_tensor.unsqueeze(0)\n",
        "  \n",
        "  # Encoderで使用するので入力の長さもリストにしておく\n",
        "  seq_len = [seq_len]\n",
        "\n",
        "  # 開始トークンを準備\n",
        "  sos_inputs = torch.tensor(sos, dtype=torch.int64)\n",
        "  input_tensor = input_tensor.to(device)\n",
        "  sos_inputs = sos_inputs.to(device)\n",
        "\n",
        "  # 入力文字列をEncoderに入れてコンテキストを得る\n",
        "  ctx = enc(input_tensor, l=seq_len)\n",
        "\n",
        "  # 開始トークンとコンテキストをDecoderの初期値にセット\n",
        "  z = sos_inputs\n",
        "  h = ctx\n",
        "  results = []\n",
        "  for i in range(max_len):\n",
        "    # Decoderで次の単語を予測\n",
        "    o, h = dec(z.view(1,1), h)\n",
        "\n",
        "    # 線形層の出力が最も大きい場所が次の単語のID\n",
        "    wi = o.detach().view(-1).max(0)[1]\n",
        "    if wi.item() == eos:\n",
        "      break\n",
        "    results.append(wi.item())\n",
        "    # 次の入力は今回の出力のIDを使用する\n",
        "    z = wi\n",
        "  # 記憶しておいた出力のIDを文字列に変換\n",
        "  return \" \".join(ds.trg_word_list[i] for i in results)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1CqMTr-2BxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9424d966-f81f-4c31-bf5f-4457aa4d969d"
      },
      "source": [
        "# 関数の動作の確認\n",
        "enc = Encoder(len(ds.src_word_list), 100, 100, 2)\n",
        "dec = Decoder(len(ds.trg_word_list), 100, 100, 2)\n",
        "translate(\"I am a student.\", enc, dec)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'quédatelo revueltos porciento gustaba desafortunadamente usara apóyame apóyame arde admitirá h2o propio sarcástico sarcástico indefensión'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00SviV3E9SwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの学習\n",
        "enc = Encoder(len(ds.src_word_list), 100, 100, 2)\n",
        "dec = Decoder(len(ds.trg_word_list), 10, 100, 2)\n",
        "enc.to(\"cuda:0\")\n",
        "dec.to(\"cuda:0\")\n",
        "# パラメータはAdam\n",
        "opt_enc = optim.Adam(enc.parameters(), 0.002)\n",
        "opt_dec = optim.Adam(dec.parameters(), 0.002)\n",
        "# 損失関数\n",
        "loss_f = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXbmKRK89MB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f72db7c2-223c-416e-8654-f73fd828f66f"
      },
      "source": [
        "# 学習\n",
        "from statistics import mean\n",
        "\n",
        "def to2D(x):\n",
        "  shapes = x.shape\n",
        "  return x.reshape(shapes[0] * shapes[1], -1)\n",
        "\n",
        "for epoc in range(30):\n",
        "  # ネットワークを訓練モードにする\n",
        "  enc.train(), dec.train()\n",
        "  losses = []\n",
        "  for x, lx, y, ly in tqdm.tqdm(loader):\n",
        "    # xのPackedSequenceを作るために翻訳元の長さで降順にソート\n",
        "    lx, sort_idx = lx.sort(descending=True)\n",
        "    x, y, ly = x[sort_idx], y[sort_idx], ly[sort_idx]\n",
        "    x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
        "    # 翻訳元をEncoderに入れてコンテキストを得る\n",
        "    ctx = enc(x, l=lx)\n",
        "\n",
        "    # yのPackedSequenceを作るために翻訳先の長さで降順にソート\n",
        "    ly, sort_idx = ly.sort(descending=True)\n",
        "    y = y[sort_idx]\n",
        "    # Decoderの初期値をセット\n",
        "    h0 = (ctx[0][:, sort_idx, :], ctx[1][:, sort_idx, :])\n",
        "    z = y[:, :-1].detach()\n",
        "\n",
        "    # -100のままだとEmbeddingの計算でエラーが出てしまうので値を0に変更しておく\n",
        "    z[z==-100] = 0\n",
        "    # Decoderに通して損失関数を計算\n",
        "    o, _ = dec(z, h0, l = ly-1)\n",
        "    loss = loss_f(to2D(o[:]), to2D(y[:, 1:max(ly)]).squeeze())\n",
        "\n",
        "    # Backpropagationを実行\n",
        "    # 勾配をゼロにする\n",
        "    enc.zero_grad(), dec.zero_grad()\n",
        "    # 誤差逆伝播法\n",
        "    loss.backward()\n",
        "    # 勾配を更新する\n",
        "    opt_enc.step(), opt_dec.step()\n",
        "    # 損失関数を更新する\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  # データセットに対して一通り計算したら現在の損失関数の値や翻訳結果を表示\n",
        "  enc.eval(), dec.eval()\n",
        "  print(epoc, mean(losses))\n",
        "  with torch.no_grad():\n",
        "    print(translate('I am a student.', enc, dec, max_len, device=\"cuda:0\"))\n",
        "    print(translate(\"He likes to eat pizza.\",enc, dec, max_len, device=\"cuda:0\"))\n",
        "    print(translate(\"She is my mother.\",enc, dec, max_len, device=\"cuda:0\"))\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.39it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 5.488104742747419\n",
            "un poco .\n",
            "a tom a tiempo .\n",
            "mi mi padre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.74it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 3.4714398600183585\n",
            "un error .\n",
            "a nadie .\n",
            "a mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 60.67it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 2.218498650634397\n",
            "un estudiante .\n",
            "a nadie .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.05it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 1.696375139746421\n",
            "un estudiante .\n",
            "a comer .\n",
            "es mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.07it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 1.4431026473866488\n",
            "un estudiante .\n",
            "a comer como comer .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.20it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 1.2708912077267005\n",
            "un estudiante .\n",
            "a comer a comer .\n",
            "es mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 64.53it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 1.1405899618687587\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "es mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.50it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 1.0382784509946932\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.42it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 0.9568050959319147\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "es mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.04it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 0.8905366038988004\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.25it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 0.8369986615152157\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.07it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11 0.7913984891151014\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 63.02it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12 0.751652119346976\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 60.81it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13 0.718876376000776\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.06it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14 0.6892945402338425\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.13it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15 0.6640722540750245\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 62.02it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "16 0.6412687392033118\n",
            "a estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 62.00it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17 0.6203101562589317\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 63.66it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "18 0.6030126099680125\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.35it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19 0.5849999731040794\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.30it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20 0.5699995981422435\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.24it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "21 0.5562672111202943\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:26<00:00, 61.50it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "22 0.5426408112409252\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.06it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "23 0.530776603632463\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 61.05it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24 0.5190069630246869\n",
            "un estudiante .\n",
            "a comer pizza .\n",
            "a mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 60.67it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25 0.5093481370329497\n",
            ".\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1655/1655 [00:27<00:00, 60.94it/s]\n",
            "  0%|          | 0/1655 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "26 0.49907839807859\n",
            "soy estudiante .\n",
            "a comer pizza .\n",
            "mi madre .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 351/1655 [00:05<00:21, 60.15it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElnhvZQb4TnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LErwQvYE85UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}