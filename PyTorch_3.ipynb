{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/PyTorch/blob/master/PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAOHHDYbEu2_",
        "colab_type": "text"
      },
      "source": [
        "# PyTorchのインストール\n",
        "+ Colabの編集→ノートブックの設定でGPUモードにすることをお忘れなく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlpBf3IKDFa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WwXlb0YDmQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsyLenx3E0b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDudM7UfFbDV",
        "colab_type": "text"
      },
      "source": [
        "インストールできたかの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q78xEOX1FQbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ge4WLbSFe2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.tensor([1, 2, 3]).to(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj_rcAHbNNs-",
        "colab_type": "code",
        "outputId": "8f2cb0c3-a96a-4852-f837-c8746c331687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLBrtJ1pNTM5",
        "colab_type": "code",
        "outputId": "414ec173-e07d-468a-dddf-2b320dd64e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# drive mean root directory of  google drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls drive/\"Colab Notebooks\"/PyTorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionMNIST  PyTorch_2.ipynb  PyTorch.ipynb  Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqce7TQpg2md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
        "import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrzCWuPyhkWc",
        "colab_type": "text"
      },
      "source": [
        "# Chapter5\n",
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jee_mPdig5z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10000種類のトークンを20次元のベクトルで表現\n",
        "emb = nn.Embedding(10000, 20, padding_idx=0) # トークンの数、embeddingの数\n",
        "\n",
        "# Embedding層への入力はint64のTensor\n",
        "inp = torch.tensor([1, 2, 5, 2, 10], dtype=torch.int64)\n",
        "\n",
        "# 出力はfloat32のTensor\n",
        "out = emb(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvixmHZgiFj1",
        "colab_type": "code",
        "outputId": "0020a7bd-e76f-451a-b357-69441707d274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3071,  0.7800, -0.4079, -0.5493,  0.1104,  0.1936, -0.2991, -0.6101,\n",
              "          0.3542,  0.2485,  0.6236,  2.1196,  1.0828,  0.6099,  0.4534, -0.3325,\n",
              "         -0.5995,  0.5519, -1.2786, -0.1574],\n",
              "        [-0.2907, -0.1377, -0.3279, -0.0847, -0.1782,  0.5321, -0.5360, -0.1514,\n",
              "         -0.5574,  1.3574,  1.8059,  0.6890,  0.3260, -0.4898,  0.5074,  0.8951,\n",
              "          0.0656,  0.0839, -0.4245, -0.7064],\n",
              "        [ 1.3226,  0.2486, -2.8225,  0.0311,  0.5486, -1.2720, -0.8503, -0.4235,\n",
              "          1.8996, -0.9953,  0.3081,  1.2451, -0.9237, -0.4128,  0.3147,  0.4796,\n",
              "          0.5280,  0.4853,  0.7573, -1.3690],\n",
              "        [-0.2907, -0.1377, -0.3279, -0.0847, -0.1782,  0.5321, -0.5360, -0.1514,\n",
              "         -0.5574,  1.3574,  1.8059,  0.6890,  0.3260, -0.4898,  0.5074,  0.8951,\n",
              "          0.0656,  0.0839, -0.4245, -0.7064],\n",
              "        [ 1.3111,  0.7227,  0.9497, -1.3358,  1.1636, -0.8808,  0.4602,  1.1967,\n",
              "         -1.3335,  1.1357,  0.4192,  0.0654,  2.0514, -1.8228,  0.4157, -0.6180,\n",
              "         -1.6910,  1.4438, -1.7638, -0.3639]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOu1G2GiLiH",
        "colab_type": "code",
        "outputId": "d69b0baa-4145-4bd6-8eab-84d0ee7f612e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-03 11:37:47--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.5MB/s    in 7.1s    \n",
            "\n",
            "2019-12-03 11:37:55 (11.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH5ghJTsjVCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cye5Y30LjcQ9",
        "colab_type": "code",
        "outputId": "17e40e12-3509-4445-84fd-b0551301d4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34maclImdb\u001b[0m/  aclImdb_v1.tar.gz  adc.json  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS_qaYfKjk7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テキストデータを前処理するための関数の用意\n",
        "# globモジュールはUnixシェルで使われているルールに従い指定されたパターンに一致するすべてのパス名を見つけ出すもの。\n",
        "# pathlibモジュールはオブジェクト指向のファイルシステムパス。\n",
        "\n",
        "import glob\n",
        "import pathlib\n",
        "import re\n",
        "\n",
        "remove_marks_regex = re.compile(\"[,\\.\\(\\)\\[\\]\\*:;]|<.*?>\")\n",
        "shift_marks_regex = re.compile(\"([?!])\")\n",
        "\n",
        "# 長い文字列をトークンIDのリストに変換する関数\n",
        "def text2ids(text, vocab_dict):\n",
        "  # !?以外の記号の削除\n",
        "  text = remove_marks_regex.sub(\"\", text)\n",
        "  # !?と単語の間にスペースを挿入\n",
        "  text = shift_marks_regex.sub(r\" \\l \", text)\n",
        "  tokens = text.split()\n",
        "  # ボキャブラリー含まれないトークンはID=0を割り当てる\n",
        "  return [vocab_dict.get(token, 0) for token in tokens]\n",
        "\n",
        "# IDのリストをint64のTensorに変換\n",
        "def list2tensor(token_idxes, max_len=100, padding=True):\n",
        "  # 各文章の分割語のトークンの数を制限\n",
        "  if len(token_idxes) > max_len:\n",
        "    token_idxes = token_idxes[:max_len]\n",
        "\n",
        "  n_tokens = len(token_idxes)\n",
        "\n",
        "  if padding:\n",
        "    # 数が足りない場合は末尾を0で埋める\n",
        "    token_idxes = token_idxes + [0]*(max_len - len(token_idxes))\n",
        "  return torch.tensor(token_idxes, dtype=torch.int64), n_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKEz5V6bj0rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ポジネガ分析用のDatasetクラスの作成\n",
        "class IMDBDataset(Dataset):\n",
        "  def __init__(self, dir_path, train=True,\n",
        "               max_len=100, padding=True):\n",
        "    self.max_len = max_len\n",
        "    self.padding = padding\n",
        "\n",
        "    path = pathlib.Path(dir_path)\n",
        "    vocab_path = path.joinpath(\"imdb.vocab\")\n",
        "\n",
        "    # ボキャブラリファイルを読み込み、行ごとに分割\n",
        "    self.vocab_array = vocab_path.open().read().strip().splitlines()\n",
        "\n",
        "    # 単語をキーとし、値がIDのdictを作る\n",
        "    self.vocab_dict = dict((w, i+1) for (i, w) in enumerate(self.vocab_array))\n",
        "\n",
        "    if train:\n",
        "      target_path = path.joinpath(\"train\")\n",
        "\n",
        "    else:\n",
        "      target_path = path.joinpath(\"test\")\n",
        "\n",
        "    pos_files = sorted(glob.glob(str(target_path.joinpath(\"pos/*.txt\"))))\n",
        "    neg_files = sorted(glob.glob(str(target_path.joinpath(\"neg/*.txt\"))))\n",
        "\n",
        "    # posは1、negは0のlabelを付けて\n",
        "    # (file_path, label)のtupleのリストを作成\n",
        "    self.labeled_files = list(zip([0]*len(neg_files), neg_files)) + list(zip([1]*len(pos_files), pos_files))\n",
        "\n",
        "  @property\n",
        "  def vocab_size(self):\n",
        "    return len(self.vocab_array)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labeled_files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label, f = self.labeled_files[idx]\n",
        "\n",
        "    # ファイルのテキストデータを読み取って小文字に変換\n",
        "    data = open(f).read().lower()\n",
        "\n",
        "    # テキストデータをIDのリストに変換\n",
        "    data = text2ids(data, self.vocab_dict)\n",
        "\n",
        "    # IDのリストをTensorに変換\n",
        "    data, n_tokens = list2tensor(data, self.max_len, self.padding)\n",
        "\n",
        "    return data, label, n_tokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVhwo3sruvrg",
        "colab_type": "code",
        "outputId": "d336e2a3-d7a3-479f-89c1-f50319465880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pE0w2IdtoBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練用とテスト用のDataLoaderの作成\n",
        "train_data = IMDBDataset(\"/content/aclImdb/\")\n",
        "test_data = IMDBDataset(\"/content/aclImdb/\", train=False)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32,\n",
        "                          shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=32,\n",
        "                          shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r_rlVVevTsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークの定義と訓練\n",
        "# 入力XをEmbeddingでベクトルの時系列に変換して、これをRNNに入れて最後に出力が1次元の線形層につなげる\n",
        "\n",
        "class SequenceTaggingNet(nn.Module):\n",
        "  def __init__(self, num_embeddings,\n",
        "               embedding_dim=50,\n",
        "               hidden_size=50,\n",
        "               num_layers=1,\n",
        "               dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "    self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x, h0=None, l=None):\n",
        "    # IDをEmbeddingで多次元のベクトルに変換する\n",
        "    # xは(batch_size, step_size, embedding_size)\n",
        "    # -> (batch_size, step_size, hidden_dim)\n",
        "    x = self.emb(x)\n",
        "\n",
        "    # 初期状態h0とともにRNNにxを渡す\n",
        "    # xは(batch_size, step_size, embedding_dim)\n",
        "    # -> (batch_size, step_size, hidden_dim)\n",
        "    x, h = self.lstm(x, h0)\n",
        "\n",
        "    # 最後のステップのみ取り出す\n",
        "    # xは(batch_size, step_size, hidden_dim)\n",
        "    # -> (batch_size, 1)\n",
        "    if l is not None:\n",
        "      # 入力のもともとの長さがある場合はそれを使用する\n",
        "      x = x[list(range(len(x))), l-1, :]\n",
        "\n",
        "    else:\n",
        "      # なければ単純に最後を使用する\n",
        "      x = x[:, -1, :] \n",
        "\n",
        "    # 取り出した最後のステップを線形層に入れる\n",
        "    x = self.linear(x)\n",
        "\n",
        "    # 余分な次元を削除する\n",
        "    # (batch_size, 1) -> (batch_size, )\n",
        "    x = x.squeeze()\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-aMUy8e2ckT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練の作成\n",
        "\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "  net.eval()\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "\n",
        "  for x, y, l in data_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    l = l.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      y_pred = net(x, l=l)\n",
        "      y_pred = (y_pred > 0).long()\n",
        "      ys.append(y)\n",
        "      ypreds.append(y_pred)\n",
        "\n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "    acc = (ys == ypreds).float().sum() / len(ys)\n",
        "    return acc.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNGpW9QY4g07",
        "colab_type": "code",
        "outputId": "292f453a-3887-498e-e600-f97231c6d8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# 評価の作成\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "# num_embeddingsには0を含めてtrain_data.vocab+1を入れる\n",
        "net = SequenceTaggingNet(train_data.vocab_size + 1, num_layers=2)\n",
        "net.to(\"cuda:0\")\n",
        "opt = optim.Adam(net.parameters())\n",
        "loss_f = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "  losses = [] # 損失関数の初期化\n",
        "  net.train() # ニューラルネットの初期化\n",
        "\n",
        "  for x, y, l in tqdm.tqdm(train_loader):\n",
        "    # データをGPUに送る\n",
        "    x = x.to(\"cuda:0\")\n",
        "    y = y.to(\"cuda:0\")\n",
        "    l = l.to(\"cuda:0\")\n",
        "\n",
        "    y_pred = net(x, l=l) # 予測結果\n",
        "    loss = loss_f(y_pred, y.float()) # 損失関数の計算\n",
        "    net.zero_grad() # 前回のbackwardメソッドで計算された勾配の値を削除\n",
        "    loss.backward() # 微分の計算\n",
        "    opt.step() # 勾配を更新\n",
        "    losses.append(loss.item()) # 損失関数のappend\n",
        "  train_acc = eval_net(net, train_loader, \"cuda:0\") # 訓練における評価\n",
        "  val_acc = eval_net(net, test_loader, \"cuda:0\") # バリデーションにおける評価\n",
        "  print(epoch, mean(losses), train_acc, val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.40it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.6893604791835141 0.53125 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.80it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 0.6694488896204688 0.78125 0.5625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 53.97it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 0.5336281067651251 0.78125 0.59375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.67it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 0.4034223910754599 0.90625 0.84375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.65it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 0.32034806920515607 0.84375 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.16it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 0.2555158994663173 0.875 0.71875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 54.45it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 0.2005250816736037 0.9375 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 48.07it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 0.15167732976610437 0.96875 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.93it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 0.11278490032024129 0.9375 0.71875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 48.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 0.08585180637552915 1.0 0.78125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC43fQDD7Bno",
        "colab_type": "code",
        "outputId": "ef0e4cd9-de2e-4c8e-9ca2-c6d87ccc0775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# RNNを使用しないモデルの作成\n",
        "\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "train_X, train_y = load_svmlight_file(\"/content/aclImdb/train/labeledBow.feat\")\n",
        "\n",
        "test_X, test_y = load_svmlight_file(\"/content/aclImdb/test/labeledBow.feat\",\n",
        "                                    n_features = train_X.shape[1])\n",
        "\n",
        "model = LogisticRegression(C=0.1, max_iter=1000)\n",
        "model.fit(train_X, train_y)\n",
        "model.score(train_X, train_y), model.score(test_X, test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.89888, 0.39596)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8aA3i52NNO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 可変長の系列の扱い\n",
        "\n",
        "class SequenceTaggingNet2(SequenceTaggingNet):\n",
        "\n",
        "  def forward(self, x, h0=None, l=None):\n",
        "    # IDをEmbeddingで多次元のベクトルに変換\n",
        "    x = self.emb(x)\n",
        "\n",
        "    # 長さ情報が与えられている場合はPackedSequenceを作る\n",
        "    if l is not None:\n",
        "      x = nn.utils.rnn.pack_padded_sequence(\n",
        "          x, l, batch_first=True\n",
        "      )\n",
        "\n",
        "    # RNNに通す\n",
        "    x, h = self.lstm(x, h0)\n",
        "\n",
        "    # 最後のステップを取り出して線形層を入れる\n",
        "    if l is not None:\n",
        "      # 長さ情報がある場合は最後の層の内部状態のベクトルを直接利用できる\n",
        "      # LSTMは通常の内部状態の他にブロックセルの状態もあるので、内部状態のみを使用する\n",
        "      hidden_state, cell_state = h\n",
        "      x = hidden_state[-1]\n",
        "\n",
        "    else:\n",
        "      x = x[:, -1, :]\n",
        "\n",
        "    # 線形層に入れる\n",
        "    x = self.linear(x).squeeze()\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibm5y75gNOHD",
        "colab_type": "code",
        "outputId": "a87018c5-9e4c-476e-c207-cac5df3b79ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# 訓練部の作成\n",
        "\n",
        "for epoch in range(10):\n",
        "  losses = []\n",
        "  net.train()\n",
        "  for x, y, l in tqdm.tqdm(train_loader):\n",
        "    # 長さの配列を長い順にソート\n",
        "    l, sort_idx = torch.sort(l, descending=True)\n",
        "    # 得られたインデクスを使用してx,yも並べ替え\n",
        "    x = x[sort_idx]\n",
        "    y = y[sort_idx]\n",
        "\n",
        "    x = x.to(\"cuda:0\")\n",
        "    y = y.to(\"cuda:0\")\n",
        "\n",
        "    y_pred = net(x, l=l)\n",
        "    loss = loss_f(y_pred, y.float())\n",
        "    net.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  train_acc = eval_net(net, train_loader, \"cuda:0\")\n",
        "  val_acc = eval_net(net, test_loader, \"cuda:0\")\n",
        "  print(epoch, mean(losses), train_acc, val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 53.94it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.06700480434343295 1.0 0.78125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.36it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 0.0515684007739653 1.0 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.24it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 0.043164286317954034 1.0 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.48it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 0.03688218970330494 1.0 0.71875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 51.63it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 0.030052903508457837 1.0 0.71875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.52it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 0.02535036737483371 1.0 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 52.98it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 0.024054053583411058 1.0 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 47.52it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 0.017573157786507792 1.0 0.78125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 46.79it/s]\n",
            "  0%|          | 0/782 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 0.016605320932117917 1.0 0.65625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:16<00:00, 46.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 0.019202219441865363 1.0 0.78125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WcAdc-m76ev",
        "colab_type": "text"
      },
      "source": [
        "## RNNによる文書生成\n",
        "https://github.com/spro/practical-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AMC8GYlTZzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ準備\n",
        "\n",
        "# すべてのascii文字で辞書を作る\n",
        "import string # 一般的な文字列操作\n",
        "all_chars = string.printable # 印刷可能な ASCII 文字で構成される文字列\n",
        "vocab_size = len(all_chars)\n",
        "vocab_dict = dict((c, i) for (i, c) in enumerate(all_chars) )\n",
        "\n",
        "# 文字列を数値のリストに変換する関数\n",
        "def str2ints(s, vocab_dict):\n",
        "  return [vocab_dict[c] for c in s] # ASCII文字のリストと照合して、そのインデックスを数字として返している\n",
        "\n",
        "# 数値のリストを文字列に変換する関数\n",
        "def inits2str(x, vocab_array):\n",
        "  return \"\".join([vocab_array[i] for i in x]) # 数値のリストの要素ごとにjoinで結合して文字列を作る"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxlvgku48-G0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ed5ce778-b9b3-46f8-f946-41b2698b948f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-04 13:22:15--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-12-04 13:22:15 (14.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxN9Zqkb-vhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasetクラスの作成\n",
        "# 巨大なテキストファイルを200文字などの文章に分割する\n",
        "\n",
        "class ShakespearDataset(Dataset):\n",
        "  def __init__(self, path, chunk_size=200):\n",
        "    # ファイルを読み込み、数値のリストに変換する\n",
        "    data = str2ints(open(path).read().strip(), vocab_dict) # strip()は文字列の先頭および末尾部分を除去したコピーを返す\n",
        "\n",
        "    # Tensorに変換し、splitする\n",
        "    data = torch.tensor(data, dtype=torch.int64).split(chunk_size)\n",
        "\n",
        "    # 最後のchunkの長さをチェックして足り無い場合は捨てる\n",
        "    if len(data[-1]) < chunk_size:\n",
        "      data = data[:-1]\n",
        "\n",
        "    self.data = data\n",
        "    self.n_chunks = len(self.data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_chunks\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return  self.data[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OwykPDZBwAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open(\"/content/input.txt\").read().strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcNi-OMpBTtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataLoaderの作成\n",
        "ds = ShakespearDataset(\"/content/input.txt\", chunk_size=200)\n",
        "loader = DataLoader(ds, batch_size=32, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoKocJQpBoVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの構築\n",
        "\n",
        "class SequenceGenerationNet(nn.Module):\n",
        "  def __init__(self, num_embeddings,\n",
        "               embedding_dim=50,\n",
        "               hidden_size=50,\n",
        "               num_layers=1,\n",
        "               dropout=0.2):\n",
        "    super().__init__()\n",
        "    # embedding層\n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    # LSTM層\n",
        "    self.lstm = nn.LSTM(embedding_dim,\n",
        "                        hidden_size,\n",
        "                        num_layers,\n",
        "                        batch_first=True,\n",
        "                        dropout=dropout)\n",
        "    # Linearのoutputのサイズは最初のEmbeddingのinputサイズと同じnum_embeddings\n",
        "    self.linear = nn.Linear(hidden_size, num_embeddings)\n",
        "\n",
        "  def forward(self, x, h0=None):\n",
        "    x = self.emb(x) # embedding\n",
        "    x, h = self.lstm(x, h0) # LSTM\n",
        "    x = self.linear(x) # LSTMの出力に対して線形変換をする\n",
        "    return x, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Yz-4sxGqFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 文章を生成する関数\n",
        "\n",
        "def generate_seq(net, start_phrase=\"The King said \", \n",
        "                 length=200, temperature=0.8, device=\"cpu\"):\n",
        "  # モデルを評価モードにする\n",
        "  net.eval()\n",
        "\n",
        "  # 出力の数値を格納するリスト\n",
        "  result = []\n",
        "\n",
        "  # 開始文字列をTensorに変換\n",
        "  start_tensor = torch.tensor(\n",
        "      str2ints(start_phrase, vocab_dict),\n",
        "      dtype=torch.int64\n",
        "  ).to(device)\n",
        "\n",
        "  # 戦闘にbatch次元を付ける\n",
        "  x0 = start_tensor.unsqueeze(0)\n",
        "\n",
        "  # RNNに通して出力と新しい内部状態を得る\n",
        "  o, h = net(x0)\n",
        "\n",
        "  # 出力を（正規化されていない）確率に変換\n",
        "  out_dist = o[:, -1].view(-1).exp()\n",
        "\n",
        "  # 確率から実際の文字のインデクスをサンプリング\n",
        "  top_i = torch.multinomial(out_dist, 1)[0] # 多項分布からサンプリング\n",
        "\n",
        "  # 結果を保存\n",
        "  result.append(top_i)\n",
        "\n",
        "  # 生成された結果を次々にRNNに入力していく\n",
        "  for i in range(length):\n",
        "    inp = torch.tensor([[top_i]], dtype=torch.int64)\n",
        "    inp = inp.to(device)\n",
        "    o, h = net(inp, h)\n",
        "    out_dist = o.view(-1).exp()\n",
        "    top_i = torch.multinomial(out_dist, 1)[0]\n",
        "    result.append(top_i)\n",
        "\n",
        "  # 開始文字列と生成された文字れるをまとめて返す\n",
        "  return start_phrase + inits2str(result, all_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWk6_fMgKadF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの訓練\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "net = SequenceGenerationNet(vocab_size, 20, 50,\n",
        "                            num_layers=2, dropout=0.1)\n",
        "net.to(\"cuda:0\")\n",
        "\n",
        "opt = optim.Adam(net.parameters())\n",
        "\n",
        "# 多クラスの識別で問題なのでSoftmaxCrossEntropyLossが損失関数となる\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50):\n",
        "  net.train()\n",
        "  losses = []\n",
        "  for data in tqdm.tqdm(loader):\n",
        "    # xは始めから最後の手前の文字まで\n",
        "    x = data[:, :-1]\n",
        "    # yは2文字目から最後の文字まで\n",
        "    y = data[:, 1:]\n",
        "\n",
        "    x = x.to(\"cuda:0\")\n",
        "    y = y.to(\"cuda:0\")\n",
        "\n",
        "    y_pred, _ = net(x)\n",
        "\n",
        "    # batchとstepの軸を統合してからCrossEntropyLossにわたす\n",
        "    loss = loss_f(y_pred.view(-1, vocab_size), y.view(-1)) # 損失関数の計算\n",
        "    net.zero_grad() # 前回の勾配をリセット\n",
        "    loss.backward() # 自動微分\n",
        "    opt.step() # 更新\n",
        "    losses.append(loss.item()) # 損失関数へのappend\n",
        "\n",
        "  # 現在の損失関数と生成される文章の例を表示\n",
        "  print(epoch, mean(losses))\n",
        "  with torch.no_grad(): # set all the requires_grad flag to false\n",
        "    print(generate_seq(net, device=\"cuda:0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Ygx8XdQkrC",
        "colab_type": "text"
      },
      "source": [
        "100%|██████████| 175/175 [00:14<00:00, 12.75it/s]49 1.6556574508122035\n",
        "The King said their make,\n",
        "My juck, I'll be make.\n",
        "\n",
        "GRINE RICES:\n",
        "That quike a's I, seem, I speak thou awain.\n",
        "\n",
        "EXHO:\n",
        "Go as you world or a-tay purfo?\n",
        "Jeting him speaks oum't of thit forth purther?\n",
        "Where of liegion this "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tafjrwxgMj9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}